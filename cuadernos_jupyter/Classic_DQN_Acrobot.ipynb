{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">Trabajo final de master</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencia de datos (<i>Data science</i>)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Estado de la computación cuántica en el aprendizaje por refuerzo y cómo aplicarla en DQN y Reinforce con Línea Base\n",
    "\n",
    "## Red neuronal clásica aplicada a DQN en entorno Acrobot\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se importan las librerías necesarias para ejecutar el Jupyter Notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Importamos timeit para tomar mediciones de tiempo de ejecución\n",
    "import timeit\n",
    "\n",
    "# Importamos codecarbon para tomar medidas de huella de carbono\n",
    "from codecarbon import EmissionsTracker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:08.245674Z",
     "start_time": "2023-06-01T11:21:07.123350Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "# Para importar nuestras librerías, que están en otro directorio\n",
    "sys.path.append(\"../librerias\")\n",
    "\n",
    "# Modelos de aprendizaje por refuerzo\n",
    "import Model\n",
    "\n",
    "# Experience Replay Buffer para DQN\n",
    "import experienceReplayBuffer as erb\n",
    "\n",
    "# Agentes\n",
    "import Agent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:11.828495Z",
     "start_time": "2023-06-01T11:21:08.249278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Se importa la librería gymnasium para utilizar los entornos CartPole y Acrobot\n",
    "import gym as gym"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:11.834956Z",
     "start_time": "2023-06-01T11:21:11.831984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch    # necesito la librería torch para la red neuronal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el entorno, en este caso CartPole"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcoemiliorodriguezserrano/anaconda3/lib/python3.10/site-packages/gym/envs/registration.py:592: UserWarning: \u001B[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001B[0m\n",
      "  logger.warn(\n",
      "/Users/marcoemiliorodriguezserrano/anaconda3/lib/python3.10/site-packages/gym/core.py:329: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/marcoemiliorodriguezserrano/anaconda3/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.make(\"Acrobot-v1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:11.857162Z",
     "start_time": "2023-06-01T11:21:11.838084Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se definen los hiperparámetros que se utilizarán en el modelo de aprendizaje por refuerzo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Hiperparámetros del modelo de aprendizaje por refuerzo\n",
    "lr = 0.001            #Velocidad de aprendizaje\n",
    "MEMORY_SIZE = 10000  #Máxima capacidad del buffer\n",
    "MAX_EPISODES = 2000   #Número máximo de episodios (el agente debe aprender antes de llegar a este valor)\n",
    "EPSILON = 1           #Valor inicial de epsilon\n",
    "EPSILON_DECAY = .99   #Decaimiento de epsilon\n",
    "GAMMA = 0.99          #Valor gamma de la ecuación de Bellman\n",
    "BATCH_SIZE = 16       #Conjunto a coger del buffer para la red neuronal\n",
    "BURN_IN = 1000        #Número de episodios iniciales usados para rellenar el buffer antes de entrenar\n",
    "DNN_UPD = 1          #Frecuencia de actualización de la red neuronal\n",
    "DNN_SYNC = 1      #Frecuencia de sincronización de pesos entre la red neuronal y la red objetivo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:11.904305Z",
     "start_time": "2023-06-01T11:21:11.866364Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el buffer de repetición de experiencias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "buffer = erb.experienceReplayBuffer(memory_size=MEMORY_SIZE, burn_in=BURN_IN)   # buffer experience replay"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:11.920910Z",
     "start_time": "2023-06-01T11:21:11.884374Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se define la red neuronal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_inputs = env.observation_space.shape[0]\n",
    "n_outputs = env.action_space.n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net=torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_inputs, 16, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, n_outputs, bias=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "net = QVC.QuantumNet(n_layers, n_qubits, n_actions, environment, quantum_device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:12.019158Z",
     "start_time": "2023-06-01T11:21:11.904560Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea la red objetivo también como un circuito cuántico"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "target_network = QVC.QuantumNet(n_layers, n_qubits, n_actions, environment, quantum_device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:12.048065Z",
     "start_time": "2023-06-01T11:21:12.028031Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el modelo DQN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dqn = Model.DQN(env, net, learning_rate=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:12.064781Z",
     "start_time": "2023-06-01T11:21:12.043370Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el modelo DQN objetivo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dqn_target = Model.DQN(env, target_network, learning_rate=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:12.065507Z",
     "start_time": "2023-06-01T11:21:12.049973Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el agente, se le pasa como parámetro los dos modelos inicializados que contienen un circuito cuántico"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "agent = Agent.DQNAgent(env, dqn, dqn_target, buffer, EPSILON, EPSILON_DECAY, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:12.077764Z",
     "start_time": "2023-06-01T11:21:12.062397Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se prepara el entorno para iniciar las mediciones de CO2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Se define la carpeta de salida de los archivos de emisiones\n",
    "output_dir = './emisiones/emisiones_Classic_DQN_Acrobot'\n",
    "\n",
    "# Se crea una instancia de EmissionsTracker y se configura la carpeta de salida\n",
    "tracker = EmissionsTracker(output_dir=output_dir, log_level = \"critical\")\n",
    "\n",
    "# Se inicializa el seguimiento de las emisiones\n",
    "tracker.start()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:14.686952Z",
     "start_time": "2023-06-01T11:21:12.073124Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iniciamos el cronómetro para medir el tiempo del proceso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tiempo_inicio = timeit.default_timer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T11:21:14.700599Z",
     "start_time": "2023-06-01T11:21:14.696792Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se inicia el entrenamiento del agente"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rellenando el buffer de repetición...\n",
      "Entrenando...\n",
      "Episodio 825 Recompensa media 50.14 Epsilon 0.01\t\t2118606165716\t\t\t"
     ]
    }
   ],
   "source": [
    "agent.train(gamma=GAMMA, max_episodes=MAX_EPISODES,\n",
    "              batch_size=BATCH_SIZE, dnn_update_frequency=DNN_UPD, dnn_sync_frequency=DNN_SYNC)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-01T11:21:14.702980Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se calcula el tiempo de ejecución, lo que ha tardado el agente en entrenar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tiempo_ejecucion = round(timeit.default_timer() - tiempo_inicio, 0)\n",
    "print(\"Tiempo ejecución entrenamiento: \" + str(int(tiempo_ejecucion/3600))\n",
    "      + \" horas, \" + str(int((tiempo_ejecucion % 3600)/60)) + \" minutos y \"\n",
    "      + str(int((tiempo_ejecucion % 3600)%60)) + \" segundos\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se calculan las emisiones que han podido implicar el proceso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emisiones = tracker.stop()\n",
    "print(\"Emisiones de CO2 (Kg)\" + str(emisiones))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se procede a graficar los resultados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.plot_rewards()\n",
    "agent.plot_loss()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
