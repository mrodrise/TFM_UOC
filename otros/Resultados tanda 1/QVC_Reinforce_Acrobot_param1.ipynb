{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">Trabajo final de master</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencia de datos (<i>Data science</i>)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Estado de la computación cuántica en el aprendizaje por refuerzo y cómo aplicarla en DQN y Reinforce con Línea Base\n",
    "\n",
    "## QVC aplicado a Reinforce en entorno Acrobot\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se importan las librerías necesarias para ejecutar el Jupyter Notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Importamos timeit para tomar mediciones de tiempo de ejecución\n",
    "import timeit\n",
    "\n",
    "# Importamos codecarbon para tomar medidas de huella de carbono\n",
    "from codecarbon import EmissionsTracker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:23.295231Z",
     "start_time": "2023-06-13T11:15:22.133859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "# Para importar nuestras librerías, que están en otro directorio\n",
    "sys.path.append(\"../librerias\")\n",
    "\n",
    "# Librería con circuito cuántico definido\n",
    "import QVC\n",
    "\n",
    "# Modelos de aprendizaje por refuerzo\n",
    "import Model\n",
    "\n",
    "# Agentes\n",
    "import Agent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.633749Z",
     "start_time": "2023-06-13T11:15:23.300628Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Se importa la librería gymnasium para utilizar los entornos CartPole y Acrobot\n",
    "import gym as gym"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.639043Z",
     "start_time": "2023-06-13T11:15:26.635171Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch    # necesario para la capa softmax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.646195Z",
     "start_time": "2023-06-13T11:15:26.641889Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el entorno, en este caso Acrobot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcoemiliorodriguezserrano/anaconda3/lib/python3.10/site-packages/gym/core.py:329: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/marcoemiliorodriguezserrano/anaconda3/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.make(\"Acrobot-v1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.674660Z",
     "start_time": "2023-06-13T11:15:26.651867Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se definen los hiperparámetros que se utilizarán en el modelo de aprendizaje por refuerzo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Hiperparámetros del modelo de aprendizaje por refuerzo\n",
    "lr = 0.01            #Velocidad de aprendizaje\n",
    "MAX_EPISODES = 1500   #Número máximo de episodios (el agente debe aprender antes de llegar a este valor)\n",
    "GAMMA = 0.99          #Valor gamma de la ecuación de Bellman\n",
    "BATCH_SIZE = 10      #Conjunto a coger del buffer para la red neuronal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.674842Z",
     "start_time": "2023-06-13T11:15:26.669017Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se definen los hiperparámetros del circuito QVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Hiperparámetros del QVC\n",
    "n_layers = 5    # número de capas del Ansatz\n",
    "n_qubits = 6   # qubits definidos, en este caso son 6 al disponer de 6 variables de observación\n",
    "n_actions = 3   # número de acciones, se definen 3 para Acrobot\n",
    "environment = 1 # entorno Acrobot\n",
    "quantum_device = \"default.qubit\" # dispositivo cuántico, se define un simulador cuántico"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.683351Z",
     "start_time": "2023-06-13T11:15:26.678430Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se define el circuito cuántico que sustituye a la red neuronal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "net = QVC.QuantumNet(n_layers, n_qubits, n_actions, environment, quantum_device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.824706Z",
     "start_time": "2023-06-13T11:15:26.686454Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el modelo Reinforce con línea base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "reinforce = Model.PGReinforce(env, net, learning_rate=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.938591Z",
     "start_time": "2023-06-13T11:15:26.828855Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se crea el agente, se le pasa como parámetro los dos modelos inicializados que contienen un circuito cuántico"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "agent = Agent.ReinforceAgent(env, reinforce)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:26.948869Z",
     "start_time": "2023-06-13T11:15:26.938818Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se prepara el entorno para iniciar las mediciones de CO2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Se define la carpeta de salida de los archivos de emisiones\n",
    "output_dir = './emisiones/emisiones_QVC_Reinforce_Acrobot'\n",
    "\n",
    "# Se crea una instancia de EmissionsTracker y se configura la carpeta de salida\n",
    "tracker = EmissionsTracker(output_dir=output_dir, log_level = \"critical\")\n",
    "\n",
    "# Se inicializa el seguimiento de las emisiones\n",
    "tracker.start()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:31.607470Z",
     "start_time": "2023-06-13T11:15:26.939162Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iniciamos el cronómetro para medir el tiempo del proceso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tiempo_inicio = timeit.default_timer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:15:31.616295Z",
     "start_time": "2023-06-13T11:15:31.612548Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se inicia el entrenamiento del agente"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando...\n",
      "Episodio 10 Recompensa media -500.00\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 18 Recompensa media -500.00\t\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n"
     ]
    }
   ],
   "source": [
    "agent.train(gamma=GAMMA, max_episodes=MAX_EPISODES,\n",
    "              batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T11:15:31.619867Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se calcula el tiempo de ejecución, lo que ha tardado el agente en entrenar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timeit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tiempo_ejecucion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(\u001B[43mtimeit\u001B[49m\u001B[38;5;241m.\u001B[39mdefault_timer() \u001B[38;5;241m-\u001B[39m tiempo_inicio, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTiempo ejecución entrenamiento: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mint\u001B[39m(tiempo_ejecucion\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m3600\u001B[39m))\n\u001B[1;32m      3\u001B[0m       \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m horas, \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mint\u001B[39m((tiempo_ejecucion \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m3600\u001B[39m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m60\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m minutos y \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m       \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mint\u001B[39m((tiempo_ejecucion \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m3600\u001B[39m)\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m60\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m segundos\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'timeit' is not defined"
     ]
    }
   ],
   "source": [
    "tiempo_ejecucion = round(timeit.default_timer() - tiempo_inicio, 0)\n",
    "print(\"Tiempo ejecución entrenamiento: \" + str(int(tiempo_ejecucion/3600))\n",
    "      + \" horas, \" + str(int((tiempo_ejecucion % 3600)/60)) + \" minutos y \"\n",
    "      + str(int((tiempo_ejecucion % 3600)%60)) + \" segundos\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T11:39:32.873200Z",
     "start_time": "2023-06-13T11:39:32.086834Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se calculan las emisiones que han podido implicar el proceso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#emisiones = tracker.stop()\n",
    "print(\"Emisiones de CO2 (Kg)\" + str(emisiones))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se procede a graficar los resultados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.plot_rewards()\n",
    "agent.plot_loss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
